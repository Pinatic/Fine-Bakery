{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64a52048",
   "metadata": {},
   "source": [
    "Made by Pieter de Jong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b9e656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "from difflib import ndiff, get_close_matches\n",
    "import textdistance\n",
    "import string\n",
    "import json\n",
    "import io\n",
    "import os\n",
    "import panel as pn\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0094a855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def startupCheck():\n",
    "    '''\n",
    "    Checks if claim_matching.json is present, creates the file if it is not present\n",
    "    '''\n",
    "    if os.path.isfile(\"claim_matching.json\") and os.access(\"claim_matching.json\", os.R_OK):\n",
    "        # checks if file exists\n",
    "        print (\"File found\")\n",
    "    else:\n",
    "        print (\"Creating file\")\n",
    "        with io.open(os.path.join(\"\", 'claim_matching.json'), 'w') as db_file:\n",
    "            db_file.write(json.dumps({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceba347",
   "metadata": {},
   "outputs": [],
   "source": [
    "startupCheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5598a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    '''\n",
    "    Creates dataframe from the columns Event Date, Product Name, and Cleams/Features of all sheets of one .xls file\n",
    "    \n",
    "    Arguments:\n",
    "    path      (str): path to .xls file\n",
    "    Returns:       : Dataframe\n",
    "    \n",
    "    Author(s):\n",
    "    Pieter de Jong\n",
    "    '''\n",
    "    df = pd.concat(pd.read_excel(path, usecols=[\"Event Date\", \"Product Name\", \"Claims/Features\"], sheet_name=None), ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88cfb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"C:\\\\Users\\\\piete\\\\AppData\\\\Roaming\\\\MobaXterm\\\\slash\\\\RemoteFiles\\\\396834_2_0\\\\2020-2022_BAK Cakes&Sweet_Goods_WE1 (8300).xls\"\n",
    "df = load_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a7d7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"/commons/dsls/fine_bakery/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dc8d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(path):\n",
    "    '''\n",
    "    Reads in all .xls files inside the folder selected using the path\n",
    "    Creates dataframe from the columns Event Date, Product Name, and Cleams/Features of all files and sheets within them\n",
    "    \n",
    "    Arguments:\n",
    "    path      (str): path to folder containing .xls files\n",
    "    Returns:       : Dataframe\n",
    "    \n",
    "    Author(s):\n",
    "    Pieter de Jong\n",
    "    '''\n",
    "    files = os.listdir(path)\n",
    "    files_xls = [file for file in files if file.endswith('xls')]\n",
    "    df = pd.concat([pd.concat(pd.read_excel(path + excelfile, usecols=[\"Event Date\", \"Product Name\", \"Claims/Features\"], sheet_name=None)) for excelfile in files_xls], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0148752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"C:\\\\Users\\\\piete\\\\Desktop\\\\fine_bakery\\\\mokup\\\\\"\n",
    "#df = load_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3f9f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(df):\n",
    "    '''\n",
    "    Cleans the dataframe by removing rows with no claims. \n",
    "    Making the Claims/Features column all lowercase.\n",
    "    Removing some unwanted characters.\n",
    "    \n",
    "    Arguments:\n",
    "    path           : Dataframe \n",
    "    Returns:       : Dataframe\n",
    "    \n",
    "    Author(s):\n",
    "    Pieter de Jong\n",
    "    '''\n",
    "    df = df.dropna(subset=[\"Claims/Features\"])\n",
    "    df[\"claims_proccesed\"] = df[\"Claims/Features\"].str.lower()\n",
    "    df[\"claims_proccesed\"] = df[\"claims_proccesed\"].str.replace(\",\", \".\").str.replace(\"\\n\", \" \").str.replace(\"\\'s\", \"\")\n",
    "    df[\"claims_proccesed\"] = df[\"claims_proccesed\"].str.rstrip(\".\").str.split(\"\\. \")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090dfa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cleaning(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bd6054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pattern(pattern, string):\n",
    "    '''\n",
    "    Returns each string containing pattern\n",
    "    \n",
    "    Arguments:\n",
    "    Pattern        : String\n",
    "    String         : String\n",
    "    Returns:       : String\n",
    "    \n",
    "    Author(s):\n",
    "    Pieter de Jong\n",
    "    '''\n",
    "    return bool(re.search(pattern, string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dc601c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nonclaims(df):\n",
    "    '''\n",
    "    Removes claims that contain patterns marking them non claims\n",
    "    \n",
    "    Arguments:\n",
    "    df             : Dataframe\n",
    "    Returns:       : Dataframe\n",
    "    \n",
    "    Author(s):\n",
    "    Pieter de Jong\n",
    "    '''\n",
    "    all_prod_claims = []\n",
    "    pattern = \": \\d|kcal|kj|\\dg|\\d g|.org\"\n",
    "    for claims in df[\"claims_proccesed\"]:\n",
    "        claims_no_ingredients = []\n",
    "        for claim in claims:\n",
    "            claim = claim.lstrip()\n",
    "            if not find_pattern(pattern, claim):\n",
    "                claims_no_ingredients.append(claim)\n",
    "        all_prod_claims.append(claims_no_ingredients)\n",
    "    df[\"claims_proccesed\"] = all_prod_claims\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd715389",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_nonclaims(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca9527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc83bff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_space_split(df):\n",
    "    '''\n",
    "    Splits sentences where a space is missing. including when next sentence starts with a number.\n",
    "    does not split abreviations like h.u.v and ignores no.1\n",
    "    \n",
    "    Arguments:\n",
    "    df             : Dataframe\n",
    "    Returns:       : Dataframe\n",
    "    \n",
    "    Author(s):\n",
    "    Pieter de Jong\n",
    "    '''\n",
    "    pattern = \"\\D\\.\\D\"\n",
    "    pattern2 = \"\\D\\.\\D\\.\"\n",
    "    pattern3 = \"\\D\\.\\d\"\n",
    "    pattern4 = \"no.1\"\n",
    "    claims_cleaned = []\n",
    "    for claims in df[\"claims_proccesed\"]:\n",
    "        temp_claims = claims\n",
    "        for claim in claims:\n",
    "            if find_pattern(pattern, claim) and not find_pattern(pattern2, claim):\n",
    "                temp_claims.remove(claim)\n",
    "                temp_claims.append(claim.split(\".\")[0])\n",
    "                temp_claims.append(claim.split(\".\")[1])\n",
    "        \n",
    "\n",
    "            if find_pattern(pattern3, claim) and not find_pattern(pattern4, claim):\n",
    "                temp_claims.remove(claim)\n",
    "                temp_claims.append(claim.split(\".\")[0])\n",
    "                temp_claims.append(claim.split(\".\")[1])\n",
    "        claims_cleaned.append(temp_claims)\n",
    "    df[\"claims_proccesed\"] = claims_cleaned\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672bf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = advanced_space_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4356ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def claim_counter(df):\n",
    "    '''\n",
    "    Create list of all unique claims and a list of all claims\n",
    "    \n",
    "    Arguments:\n",
    "    df             : Dataframe\n",
    "    Returns:       : List of claims, List of unique claims\n",
    "    \n",
    "    Author(s):\n",
    "    Pieter de Jong\n",
    "    '''\n",
    "    all_cleaned_unique_claims = []\n",
    "    all_cleaned_claims = []\n",
    "    for claims in df[\"claims_proccesed\"]:\n",
    "        for claim in claims:\n",
    "            all_cleaned_claims.append(claim)\n",
    "            if claim not in all_cleaned_unique_claims:\n",
    "                all_cleaned_unique_claims.append(claim)\n",
    "    return all_cleaned_claims, all_cleaned_unique_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3abb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cleaned_claims, all_cleaned_unique_claims = claim_counter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684e1fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Claim_ammount = Counter(all_cleaned_claims)\n",
    "Claim_ammount.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48c5a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#find all claims containing pattern and adding these claims to claim_dict with pattern as key if their tickbox is selected\n",
    "claim_dict = {}\n",
    "pattern = \"green dot certified\"\n",
    "def get_matches(pattern):\n",
    "    #pattern = \"vegan\"\n",
    "    pattern_match = []\n",
    "    for claim in all_cleaned_unique_claims:\n",
    "        if find_pattern(pattern, claim):\n",
    "            if claim not in pattern_match:\n",
    "                pattern_match.append(claim)\n",
    "    return pattern_match\n",
    "\n",
    "\n",
    "#text_input = pn.widgets.TextInput(name=\"Claim search\", placeholder=\"Enter claim here\")\n",
    "checkbox_group = pn.widgets.CheckBoxGroup(name=\"Checkbox Group\", value=get_matches(pattern), options=get_matches(pattern))\n",
    "#column = pn.Column(text_input, checkbox_group)\n",
    "#column\n",
    "checkbox_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba44f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_dict[pattern] = checkbox_group.value\n",
    "\n",
    "filename = \"claim_matching.json\"\n",
    "\n",
    "    \n",
    "with open(filename, \"r+\") as jsonfile:\n",
    "    dic = json.load(jsonfile)\n",
    "    \n",
    "    for key in claim_dict.keys():\n",
    "        dic[key] = claim_dict[key]\n",
    "\n",
    "with open(filename, \"w\") as jsonfile:\n",
    "    json.dump(dic, jsonfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bfa859",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4c1740",
   "metadata": {},
   "outputs": [],
   "source": [
    "for claims in df[\"claims_proccesed\"]:\n",
    "    print(any((True for x in dic[\"vegan\"] if x in claims)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d9138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_close_matches(\"recyclable\", [claim for claim in claims_no_ingredients], 10, 0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
